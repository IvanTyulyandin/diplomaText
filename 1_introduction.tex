\section*{Введение}

Количество доступной информации в современном мире стремительно растет.
С целью повышения скорости обработки информации используются различные подходы, такие как вычислительные кластеры, новые алгоритмы и дополнительное оборудование, например, FPGA (ПЛИС) или GPGPU (графический процессор общего назначения). 
Однако на практике не всегда есть возможность увеличить имеющиеся вычислительные мощности, и в таком случае необходимо искать способы улучшения алгоритмов.

Одним из таких способов является описание и реализация отдельных шагов существующих алгоритмов  с использованием иных понятий и формализмов.
Для многих алгоритмов отдельные шаги могут быть описаны с использованием методов линейной алгебры, например, через операции над матрицами с переопределёнными операциями поэлементного сложения и умножения.
Если описать алгоритм методами линейной алгебры и запрограммировать его с использованием промышленных библиотек, то он может значительно превзойти по скорости исходную реализацию за счет возможности эффективно распараллеливания матричных операций.
Алгоритмы, которые выражены через операции и понятия из линейной алгебры, широко используются в различных областях, таких как машинное обучение~\cite{LA_ML}, компьютерное зрение~\cite{LA_CV}, статистика~\cite{LA_STAT}, анализ программ на логических языках программирования ~\cite{part_eval_logic}, теория графов~\cite{SuiteSparse} и многих других.

Другой способ улучшения алгоритмов основан на следующем наблюдении. 
Достаточно часто случается ситуация, когда часть параметров алгоритма не меняется от запуска к запуску, т.е. они зафиксированы в течение некоторого значительного промежутка времени.
Зная фактические значения этих параметров, можно оптимизировать их использование в алгоритме. 
Таким образом, можно получить новый алгоритм, в котором вычисления, зависящие только от зафиксированных параметров, уже выполнены.
Результат выполнения нового алгоритма с оставшимися параметрами должен быть семантически эквивалентен результату выполнения исходного алгоритма на соответствующих данных. 
В сравнении с исходным алгоритмом, при повторных запусках новый алгоритм не выполняет те вычисления, которые зависят от зафиксированных параметров. 
Эти вычисления сделаны и сохранены на стадии генерации нового алгоритма.
Такая техника преобразования алгоритмов известна как “специализация”, или “частичное вычисление”, а программа, генерирующая новый алгоритм, называется “специализатор”~\cite{Jones_spec}.
На текущий момент вопрос о границах применимости специализации к алгоритмам, выраженных с помощью методов линейной алгебры, до конца не исследован.

В данной работе будет рассмотрена специализация известного алгоритма Витерби~\cite{Viterbi}, выраженного в терминах линейной алгебры~\cite{LA_Viterbi}. 
Этот алгоритм используется в биоинформатике~\cite{cudampf}, при распознавании речи~\cite{Rabiner_VA} и в финансовых расчетах~\cite{Viterbi_credit}. 
У него имеется два входных параметра: скрытая марковская модель (далее --- СММ)~\cite{Eddy_HMM} и последовательность наблюдений. 
Задачей алгоритма Витерби является вычислить  вероятность того, что последовательность наблюдений была сгенерирована именно с помощью данной СММ. 
Основная часть алгоритма Витерби существенно зависит от СММ, и в то же время на практике, как правило, используется какая-то одна марковская модель для анализа значительного количества последовательностей наблюдений. 
Следовательно, если  специализировать алгоритм Витерби скрытой марковской моделью, то это может дать значительный прирост производительности.