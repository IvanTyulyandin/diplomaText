\section{Специализация алгоритма Витерби}
В этой главе описаны подходы, которые были применены для 
специализации алгоритма Витерби.

\subsection{Описание форматов входных параметров}
Для экспериментов был создан формат описания данных в скрытой марковской модели.

\subsection{Специализация с использованием матричных\\ операций}
В статье Э. Теодосиса и П. Марагоса~\cite{LA_Viterbi} описан 
вариант представления алгоритма Витерби через матричные 
операции.
Он предназначен для работы со СММ из раздела 
\ref{lab:HMM} и рассмотрен в подразделе 
\ref{lab:LA_Viterbi}.

Рассмотрим операции алгоритма Витерби и выделим те части, которые можно специализировать, с учетом того, что 
СММ --- статический параметр.
Последовательность наблюдений $Obs$, которая является 
динамическим параметром, индексируется от 1 до $lo$ 
включительно, где $lo$ --- это длина последовательности.
Начальный шаг --- это обработка первого наблюдения из 
последовательности событий $Obs$.
\[Probs_{1} = P(Obs[1]) \times B\]
В СММ записано множество возможных наблюдений \emph{O}.
Матрицы $P(o)$ с преобразованными вероятностями для каждого 
наблюдения $o$ и столбец преобразованных вероятностей 
$B$ состояний быть начальным могут быть
получены из данных СММ.
Следовательно, можно заранее вычислить всевозможные варианты 
столбца $Probs_{1}$ как $K$ матриц $PB(o)$. 
\[PB(o) = P(o) \times B \;\;\; \forall o \in O\]
Далее в неспециализированной версии обрабатывается оставшаяся 
часть последовательности $Obs$.
\[Probs_{t} = P(Obs[t]) \times T^{\top} \times Probs_{t - 1}\]
Матрица переходов $T$ также хранится в СММ.
Это значит, что умножение матрицы $P(o)$ на $T^{T}$ 
может быть посчитано для любого наблюдения $o$ из множества $O$.
\[PT(o) = P(o) \times T^{\top} \;\;\; \forall o \in O\]
Все предпосчитанные матрицы сохраняются в памяти для 
дальнейшего переиспользования.
Псевдокод специализированного алгоритма Витерби представлен 
на листинге~\ref{Viterbi_1}.
\begin{lstlisting}[caption={Псевдокод алгоритма Витерби первого уровня специализации}, label=Viterbi_1, escapeinside={(*}{*)}]
HMM // (*\color{codegreen}{Произвольная СММ}*)
PB[HMM.K] // (*\color{codegreen}{$P(o) \times B$}*)
PT[HMM.K] // (*\color{codegreen}{$P(o) \times T^{\top}$}*)

function spec_Viterbi()
	for i = 1..HMM.K
		PB[i] = P(HMM.O[i]) (*$\times$*) HMM.B)
		PT[i] = P(HMM.O[i]) (*$\times$*) (HMM.T)(*$^{\top}$*)

function Viterbi(Obs)
	lo = length(Obs)
	Probs[1][HMM.K]

	Probs = PB(Obs[1])
	
	for i = 2..lo
		Probs = PT(Obs[i]) (*$\times$*) Probs
		
	return Probs
\end{lstlisting}

Введем понятие \emph{уровня специализации} --- это количество 
наблюдений, которое обрабатывается за одно умножение матриц 
при вычислениях со второго и последующих наблюдений.
Например, на листинге~\ref{Viterbi_1} уровень специализации 
равен одному, так как на строке 17 происходит обработка 
только одного наблюдения.

Далее можно воспользоваться тем фактом, что умножение матриц 
является ассоциативной операцией.
Это позволяет увеличить уровень специализации и тем самым 
сократить количество матричных умножений.
В формуле~\ref{lvl_2} показано, как обработать наблюдения $o_{t}$ и $o_{t-1}$ при условии, 
что $Probs_{t-2}$ известно.
\begin{align}
  \mathit{Probs}_{t} &= \mathit{PT}(\mathit{o}_{t}) \times \mathit{Probs}_{t-1}\nonumber\\
  &= \mathit{PT}(\mathit{o}_{t}) \times (\mathit{PT}(\mathit{o}_{t-1}) \times \mathit{Probs}_{t-2}) \nonumber\\
  & =(\mathit{PT}(\mathit{o}_{t}) \times \mathit{PT}(\mathit{o}_{t-1})) \times \mathit{Probs}_{t-2}
\label{lvl_2}
\end{align}
Результат умножения матриц $PT(o_t)$ и $PT(o_{t-1})$
можно получить, взяв данные из СММ.
Такой подход дает основу для повышения уровня специализации, 
который ограничен лишь количеством имеющейся памяти для хранения предпосчитанных матриц.
На формуле~\ref{lvl_3} представлен способ для обработки трех 
наблюдений.
Так как произведение $\mathit{PT}(o_t) \times \mathit{PT}(o_{t-1}) \times \mathit{PT}(o_{t-2})$
может быть вычислено на стадии специализации, необходимо 
только одно умножение матриц.
Та же самая идея может быть использована, чтобы получить 
четверый, пятый, и т.д. уровни специализации.
\begin{align}
  \mathit{Probs}_{t} = \mathit{PT}(o_t) \times \mathit{PT}(o_{t-1}) \times \mathit{PT}(o_{t-2}) \times \mathit{Probs}_{t - 3} 
\label{lvl_3}
\end{align}
Псевдокод алгоритма Витерби с произвольным уровнем 
специализации представлен на листинге~\ref{lvl_any}.
Для того, что получить нужный уровень специализации $M$, 
необходимо посчитать и сохранить произведение всевозможных 
комбинаций $M$ матриц $PT(o)$.
\begin{lstlisting}[caption={Псевдокод алгоритма Витерби произвольного уровня специализации}, label=lvl_any, escapeinside={(*}{*)}]
HMM
PB[HMM.K]
PT[HMM.K]
level
// obs_lvl_handlers (*\color{codegreen}{хранит всевозможные комбинации произведений level матриц из PT}*)
obs_lvl_handlers[HMM.K(*$^{level}$*)]

function spec_Viterbi()
	for i = 1..HMM.K
		PB[i] = P(HMM.O[i]) (*$\times$*) HMM.B)
		PT[i] = P(HMM.O[i]) (*$\times$*) (HMM.T)(*$^{\top}$*)
	calculate_combinations(obs_lvl_handlers, level, PT)

function Viterbi(Obs)
	// (*\color{codegreen}{Обработка первого наблюдения}*)
	Probs = PB[Obs[1]]

	lo = length(Obs)
	i = 2

	// (*\color{codegreen}{Пока количество необработанных наблюдений больше или равно level}*)
	while (lo - i) >= level)
		// (*\color{codegreen}{Ищем матрицу для обработки следующих level наблюдений}*)
		handler = obs_lvl_handlers.find(Obs[i:i+lvl])
		Probs = handler (*$\times$*) Probs
		i = i + level
	
	// (*\color{codegreen}{Количество необработанных наблюдений меньше, чем level}*)
	for (; i < lo; i = i + 1)
		Probs = PT[Obs[i]] (*$\times$*) Probs

	return Probs
\end{lstlisting}
В неспециализированной версии алгоритма Витерби необходимо 
выполнить $1 + 2 * (lo - 1)$ матричных умножений, где $lo$ 
--- это длина последовательности $Obs$.
При специализации уровня $M$ количество 
матричных умножений уменьшается, в таком случае нужно 
вычислить $\mathit{(lo - 1) / M + (lo - 1)\ mod\ M}$ 
произведений и выделить дополнительную память для хранения 
матриц $PT$ и $PB$ (это $2 * K$ матриц $N \times N$) и $K^{M}$ матриц $N 
\times N$ для обработки последовательности наблюдений 
размером $M$.

Таким образом, при специализации алгоритма Витерби в 
терминах линейной алгебры возможно значительное сокращение 
количества матричных операций в сравнении с 
неспециализированной версией, но при этом растет количество 
требуемой памяти.

\subsection{Реализация и тестирование  корректности}
Матрицы, которые описывают СММ, во многих случаях можно 
считать разреженными, то есть количество не нулевых элементов 
гораздо меньше, чем элементов всего.
Для работы с разреженными матрицами сообществом был создан 
стандарт \name{GraphBLAS}~\cite{GraphBLAS}.
Для проведения экспериментов по специализации алгоритма 
Витерби в терминах линейной алгебры была взята библиотека 
\name{SuiteSparse:GraphBLAS}~\cite{SuiteSparse}, 
которая де-факто считается самой производительной и является 
референсной реализацией стандарта \name{GraphBLAS}.

Специализатор считывает СММ, выполняет умножения матриц, 
которые зависят от статических данных из СММ, и результаты 
сохраняет в памяти, создавая специализированную функцию.
Далее, при вызове этой функции в зависимости от наблюдаемых 
событий, подставляются предпосчитанные матрицы.
Исходный код этого специализатора доступен по ссылке 
\href{https://github.com/IvanTyulyandin/Lin_alg_Viterbi}
{github.com/IvanTyulyandin/Lin\_alg\_Viterbi}.