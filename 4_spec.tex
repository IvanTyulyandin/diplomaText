\section{Специализация алгоритма Витерби}
В этой главе рассказывается о том, как можно выполнить 
специализацию алгоритма Витерби, выраженного методами 
линейной алгебры, где СММ является статическим, т.е. 
зафиксированным параметром.
В разделе~\ref{lab:LA_spec} представлен подход специализации 
алгоритма Витерби, который позволяет существенно сократить 
количество необходимых матричных операций за счет сохранения 
части предпосчитанных результатов в памяти.

\subsection{Специализация с использованием матричных\\ операций}
\label{lab:LA_spec}
Вариант представления
алгоритма Витерби через матричные операции представлен в~\cite{LA_Viterbi}.
Он предназначен для работы со СММ из раздела 
\ref{lab:HMM} и рассмотрен в подразделе 
\ref{lab:LA_Viterbi}.

Рассмотрим операции алгоритма Витерби и выделим те части, которые можно специализировать, с учетом того, что 
СММ --- статический параметр.
Последовательность наблюдений $Obs$, которая является 
динамическим параметром, индексируется от 1 до $lo$ 
включительно, где $lo$ --- это длина последовательности.
Начальный шаг --- это обработка первого наблюдения из 
последовательности событий $Obs$.
\[Probs_{1} = P(Obs[1]) \times B\]
В СММ записано множество возможных наблюдений \emph{O}.
Матрицы $P(o)$ с преобразованными вероятностями для каждого 
наблюдения $o$ и столбец преобразованных вероятностей 
$B$ состояний быть начальным могут быть
получены из данных СММ.
Следовательно, можно заранее вычислить всевозможные варианты 
столбца $Probs_{1}$ как $K$ матриц $PB(o)$. 
\[PB(o) = P(o) \times B \;\;\; \forall o \in O\]
Далее в неспециализированной версии обрабатывается оставшаяся 
часть последовательности $Obs$.
\[Probs_{t} = P(Obs[t]) \times T^{\top} \times Probs_{t - 1}\]
Матрица переходов $T$ также хранится в СММ.
Это значит, что результат умножения матрицы $P(o)$ на 
$T^{\top}$ может быть получен для любого наблюдения $o$ из 
множества $O$.
\[PT(o) = P(o) \times T^{\top} \;\;\; \forall o \in O\]
Все предпосчитанные матрицы сохраняются в памяти для 
дальнейшего переиспользования.
Псевдокод специализированного алгоритма Витерби представлен 
на листинге~\ref{Viterbi_1}.
\begin{lstlisting}[caption={Алгоритм Витерби первого уровня специализации}, label=Viterbi_1, escapeinside={(*}{*)}]
HMM // (*\color{codegreen}{Произвольная СММ}*)
PB[HMM.K] // (*\color{codegreen}{$P(o) \times B$}*)
PT[HMM.K] // (*\color{codegreen}{$P(o) \times T^{\top}$}*)

function spec_Viterbi()
	for i = 1..HMM.K
		PB[i] = P(HMM.O[i]) (*$\times$*) HMM.B)
		PT[i] = P(HMM.O[i]) (*$\times$*) (HMM.T)(*$^{\top}$*)

function Viterbi(Obs)
	lo = length(Obs)
	Probs[1][HMM.K]

	Probs = PB(Obs[1])
	
	for i = 2..lo
		Probs = PT(Obs[i]) (*$\times$*) Probs
		
	return Probs
\end{lstlisting}

Введем понятие \emph{уровня специализации} --- это количество 
наблюдений, которое обрабатывается за одно умножение матриц 
при вычислениях со второго и последующих наблюдений.
Например, на листинге~\ref{Viterbi_1} уровень специализации 
равен одному, так как на строке 17 происходит обработка 
только одного наблюдения.

Далее можно воспользоваться тем фактом, что умножение матриц 
является ассоциативной операцией.
Это позволяет увеличить уровень специализации и тем самым 
сократить количество матричных умножений.
В формуле~\ref{lvl_2} показано, как обработать наблюдения $o_{t}$ и $o_{t-1}$ при условии, 
что $Probs_{t-2}$ известно.
\begin{align}
  \mathit{Probs}_{t} &= \mathit{PT}(\mathit{o}_{t}) \times \mathit{Probs}_{t-1}\nonumber\\
  &= \mathit{PT}(\mathit{o}_{t}) \times (\mathit{PT}(\mathit{o}_{t-1}) \times \mathit{Probs}_{t-2}) \nonumber\\
  & =(\mathit{PT}(\mathit{o}_{t}) \times \mathit{PT}(\mathit{o}_{t-1})) \times \mathit{Probs}_{t-2}
\label{lvl_2}
\end{align}
Результат умножения матриц $PT(o_t)$ и $PT(o_{t-1})$
можно получить, взяв данные из СММ.
Такой подход дает основу для повышения уровня специализации, 
который ограничен лишь количеством имеющейся памяти для хранения предпосчитанных матриц.
На формуле~\ref{lvl_3} представлен способ для обработки трех 
наблюдений.
Так как произведение $\mathit{PT}(o_t) \times \mathit{PT}(o_{t-1}) \times \mathit{PT}(o_{t-2})$
может быть вычислено на стадии специализации, необходимо 
только одно умножение матриц.
Та же самая идея может быть использована, чтобы получить 
четверый, пятый, и т.д. уровни специализации.
\begin{align}
  \mathit{Probs}_{t} = \mathit{PT}(o_t) \times \mathit{PT}(o_{t-1}) \times \mathit{PT}(o_{t-2}) \times \mathit{Probs}_{t - 3} 
\label{lvl_3}
\end{align}
Псевдокод алгоритма Витерби с произвольным уровнем 
специализации представлен на листинге~\ref{lvl_any}.
Для того, чтобы получить нужный уровень специализации $M$, 
необходимо вычислить и сохранить произведение всевозможных 
комбинаций $M$ матриц $PT(o)$.
\begin{lstlisting}[caption={Алгоритм Витерби произвольного уровня специализации}, label=lvl_any, escapeinside={(*}{*)}]
HMM
PB[HMM.K]
PT[HMM.K]
level
// obs_lvl_handlers (*\color{codegreen}{хранит всевозможные комбинации произведений level матриц из PT}*)
obs_lvl_handlers[HMM.K(*$^{level}$*)]

function spec_Viterbi()
	for i = 1..HMM.K
		PB[i] = P(HMM.O[i]) (*$\times$*) HMM.B)
		PT[i] = P(HMM.O[i]) (*$\times$*) (HMM.T)(*$^{\top}$*)
	calculate_combinations(obs_lvl_handlers, level, PT)

function Viterbi(Obs)
	// (*\color{codegreen}{Обработка первого наблюдения}*)
	Probs = PB[Obs[1]]

	lo = length(Obs)
	i = 2

	// (*\color{codegreen}{Пока количество необработанных наблюдений больше или равно level}*)
	while (lo - i) >= level)
		// (*\color{codegreen}{Ищем матрицу для обработки следующих level наблюдений}*)
		handler = obs_lvl_handlers.find(Obs[i:i+lvl])
		Probs = handler (*$\times$*) Probs
		i = i + level
	
	// (*\color{codegreen}{Количество необработанных наблюдений меньше, чем level}*)
	for (; i < lo; i = i + 1)
		Probs = PT[Obs[i]] (*$\times$*) Probs

	return Probs
\end{lstlisting}
В неспециализированной версии алгоритма Витерби необходимо 
выполнить $1 + 2 * (lo - 1)$ матричных умножений, где $lo$ 
--- это длина последовательности $Obs$.
При специализации уровня $M$ количество 
матричных умножений уменьшается, в таком случае нужно 
вычислить $\mathit{(lo - 1) / M + (lo - 1)\ mod\ M}$ 
произведений и выделить дополнительную память для хранения 
матриц $PT$ и $PB$ (это $2 * K$ матриц $N \times N$) и $K^{M}$ матриц $N 
\times N$ для обработки последовательности наблюдений 
размером $M$.

Таким образом, при специализации алгоритма Витерби в 
терминах линейной алгебры возможно значительное сокращение 
количества матричных операций в сравнении с 
неспециализированной версией, но при этом растет количество 
требуемой памяти.

\subsection{Особенности реализации}
Целью специализации является повышение производительности 
специализируемого алгоритма.
Для проверки на улучшение производительности необходимо 
реализовать два варианта алгоритма Витерби: 
неспециализированный и с произвольным уровнем специализации, 
которые описаны в подразделе~\ref{lab:LA_Viterbi} 
и разделе~\ref{lab:LA_spec} соответственно.

\subsubsection{Выбор технологий и тестирование корректности}
При выборе библиотек для реализации нужно учитывать следующие 
факторы.
Во-первых, матрицы, которые описывают СММ, во многих случаях 
можно считать разреженными, то есть количество не нулевых 
элементов гораздо меньше, чем элементов всего.
Во-вторых, как следует из раздела~\ref{lab:exist_Viterbi}, 
есть реализации как и на центральном процессоре (CPU), так и 
на графических процессорах общего назначения (GPGPU).
Для работы с разреженными матрицами сообществом был создан 
стандарт \name{GraphBLAS}~\cite{GraphBLAS}.
Для проведения экспериментов по специализации алгоритма 
Витерби в терминах линейной алгебры была взята библиотека 
\name{Sui\-te\-Spar\-se:Graph\-BLAS}~\cite{SuiteSparse}, 
которая де-факто считается самой производительной и также 
является наиболее полной реализацией стандарта 
\name{GraphBLAS}.
Алгоритмы этой библиотеки созданы с использованием \name{OpenMP}.
К сожалению, код \name{Sui\-te\-Spar\-se:Graph\-BLAS} 
предназначен только для выполнения на CPU, а стабильных и 
соответствующих стандарту \name{GraphBLAS} реализаций для 
запуска на GPGPU пока нет.
Для проведения экспериментов на GPGPU была использована 
библиотека \name{CUSP}~\cite{CUSP}.
Обе эти библиотеки предоставляют функции для работы с 
полукольцом \emph{Min-plus}, что упрощает дальнейшую 
разработку.

Исходный код различных реализаций алгоритма Витерби доступен 
по ссылке~\cite{repo}.
Для упрощения взаимодействия с библиотеками был выбран язык 
\CPP, так как библиотека \name{Sui\-te\-Spar\-se:Graph\-BLAS} 
разработана на языке \name{C}, а библиотека \name{CUSP} --- на \CPP.
В папке \emph{Viterbi\_impl} находятся реализации
неспециализированного и специализированного алгоритма Витерби.
Папка \emph{tests} содержит следующие тесты для проверки 
отсутствия ошибок в программах:
\begin{itemize}
	\item проверка правильности чтения данных из файлов;
	\item получение ожидаемого ответа на одной конкретной СММ;
	\item сохранение семантики после специализации, то есть 
	получение одинакового ответа для всех реализаций 
	алгоритма Витерби при одинаковых входных данных.
\end{itemize} 
При взаимодействии с низкоуровневыми средствами
необходимо выявлять возможные ошибки, опечатки и утечки 
памяти, для этого используются инструменты \name{Clang-tidy} 
для статического анализа и \name{Val\-grind} для проверки на 
наличие утечек памяти и некорректных системных или 
библиотечных вызовов.
Данные инструменты не выявили проблем, связанных с кодом 
реализаций алгоритма Витерби, но обнаружили некорректные 
вызовы при инициализации \name{OpenMP} и потенциальное 
разыменование нулевого указателя в коде библиотеке \name{CUSP}.
Эти проблемы не влияют на прохождение тестов.

\subsubsection{Описание формата входных параметров}
\label{lab:formats}
Из-за того, что общепринятых форматов для описания скрытой 
марковской модели, соответствующей определению из 
раздела~\ref{lab:HMM}, и последовательности наблюдений не 
было найдено, для экспериментов был создан новый формат.
В нем и состояния, и наблюдения кодируются с помощью 
натуральных чисел.

В файле с расширением \emph{.chmm} находится СММ, которая закодирована следующим образом:
\begin{itemize}
	\item количество состояний СММ $N$;
	\item количество состояний $NZ$, для которых вероятность быть начальным ненулевая;
	\item $NZ$ строк вида:\\ 
	номер\_состояния вероятность\_быть\_начальным;
	\item количество возможных наблюдений $K$;
	\item $N$ строк, в каждой $K$ вероятностей, каждая из которых содержит вероятность наблюдения события в состоянии, т.е. элементы матрицы $E$;
	\item количество переходов $NT$;
	\item $NT$ строк вида:\\ состояние\_из состояние\_куда вероятность\_перехода.
\end{itemize}

Для описания набора последовательностей наблюдений 
предлагается следующий формат \emph{.ess}:
\begin{itemize}
	\item количество последовательностей в файле $L$;
	\item $L$ пар строк вида, где lo --- это длина последовательности:\\
	номер\_последовательности lo\\
	наблюдение\_1 наблюдение\_2 ... наблюдение\_lo.
\end{itemize}

Примеры СММ и последовательностей в таком формате могут быть 
найдены по ссылке~\cite{repo} в папках \emph{chmms\_files} и 
\emph{ess\_files} соответственно.

Так как описанный ранее метод специализации может привести 
к снижению производительности алгоритма Витерби, далее 
необходимо поставить эксперименты по сравнению 
производительности реализаций неспециализированной и 
специализированной версий алгоритма.
